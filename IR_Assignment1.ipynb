{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IR-Assignment1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNOKrI/6QVLFD1VLZIhLIU+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chandi1994/Assignment/blob/master/IR_Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5veox_a3O1E",
        "outputId": "affcd4de-a397-4dd5-e5cc-d52be42cfdd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pip install --user -U nltk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nltk\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from nltk) (0.17.0)\n",
            "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from nltk) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from nltk) (4.41.1)\n",
            "Building wheels for collected packages: nltk\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.5-cp36-none-any.whl size=1434675 sha256=afaa9221a12012ee5a0c4ee6a57df1a6c68f48da51bf266e93466c6ce5fa08e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
            "Successfully built nltk\n",
            "Installing collected packages: nltk\n",
            "\u001b[33m  WARNING: The script nltk is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "Successfully installed nltk-3.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrgYOEh83S3j"
      },
      "source": [
        "from nltk.tokenize import TweetTokenizer"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56Rh8PPS4lTv"
      },
      "source": [
        "twitter_data = open('/content/twitter.txt', 'r')\n",
        "file_content = twitter_data.read()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwsYojSEJwQE",
        "outputId": "3b91e0d2-27bd-4c30-e9b7-db5aa6699a8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "twitter_data"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.TextIOWrapper name='/content/twitter.txt' mode='r' encoding='UTF-8'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJlVk6oXJ1O7",
        "outputId": "90f27ee1-3f3b-4bc8-a727-35045d3b801b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tknzr = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
        "tknzr.tokenize(file_content)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Reminds',\n",
              " 'me',\n",
              " 'of',\n",
              " 'Liberal',\n",
              " 'Immigration',\n",
              " 'Fraudster',\n",
              " 'Monsef',\n",
              " 'avoiding',\n",
              " 'deportation',\n",
              " 'from',\n",
              " 'Canada',\n",
              " '.',\n",
              " '#cdnpoli',\n",
              " '#LPC',\n",
              " '#CPCLDR',\n",
              " '�',\n",
              " '�',\n",
              " '_',\n",
              " 'https://t.co/ZOZOSe1CqQ',\n",
              " '#immigration',\n",
              " '#integration',\n",
              " '#canada',\n",
              " 'https://t.co/M5cKGyvV8F',\n",
              " 'We',\n",
              " 'want',\n",
              " 'controlled',\n",
              " 'immigration',\n",
              " 'that',\n",
              " 'contributes',\n",
              " 'positively',\n",
              " 'to',\n",
              " 'the',\n",
              " 'UK',\n",
              " 'economy',\n",
              " '.',\n",
              " 'Same',\n",
              " 'as',\n",
              " 'Australia',\n",
              " '&',\n",
              " 'Canada',\n",
              " '.',\n",
              " 'https://t.co/99mYliuOes',\n",
              " 'Is',\n",
              " 'the',\n",
              " 'new',\n",
              " 'Manitoba',\n",
              " 'immigration',\n",
              " 'fee',\n",
              " 'a',\n",
              " 'head',\n",
              " 'tax',\n",
              " '?',\n",
              " 'https://t.co/LsG7C3vLe9',\n",
              " 'Canada',\n",
              " 'immigration',\n",
              " 'profit',\n",
              " 'influence',\n",
              " 'modernistic',\n",
              " 'delhi',\n",
              " 'yet',\n",
              " 'abhinav',\n",
              " ':',\n",
              " 'XKofy',\n",
              " 'https://t.co/becgusY2i6',\n",
              " 'Canada',\n",
              " 'Immigration',\n",
              " 'Minister',\n",
              " 'to',\n",
              " '�',\n",
              " '�',\n",
              " '�',\n",
              " 'Substantially',\n",
              " 'Increase',\n",
              " 'Immigration',\n",
              " 'Numbers',\n",
              " 'https://t.co/nEFw30MRaa',\n",
              " 'https://t.co/cyI867PZRV',\n",
              " 'M',\n",
              " '�',\n",
              " '�',\n",
              " 'me',\n",
              " 'les',\n",
              " '#USA',\n",
              " '=p',\n",
              " 'ays',\n",
              " \"d'immigration\",\n",
              " 'par',\n",
              " 'excellence',\n",
              " 'CONTR',\n",
              " '�',\n",
              " '�',\n",
              " 'LE',\n",
              " 'RIGOUREUSEMENT',\n",
              " \"l'immigration\",\n",
              " 'et',\n",
              " 'acc',\n",
              " '�',\n",
              " '�',\n",
              " 's',\n",
              " '�',\n",
              " '�',\n",
              " 'la',\n",
              " '#GreenCARD',\n",
              " '!',\n",
              " '�',\n",
              " '�',\n",
              " '_',\n",
              " 'https://t.co/IHpVhW2BaG',\n",
              " 'what',\n",
              " 'changes',\n",
              " 'should',\n",
              " 'be',\n",
              " 'made',\n",
              " 'to',\n",
              " \"Canada's\",\n",
              " 'immigration',\n",
              " 'laws',\n",
              " 'due',\n",
              " 'to',\n",
              " 'the',\n",
              " 'influx',\n",
              " 'of',\n",
              " 'immigration',\n",
              " 'and',\n",
              " 'violence',\n",
              " '?',\n",
              " 'L',\n",
              " '�',\n",
              " '�',\n",
              " 'immigration',\n",
              " 'irr',\n",
              " '�',\n",
              " '�',\n",
              " 'guli',\n",
              " '�',\n",
              " '�',\n",
              " 're',\n",
              " 'au',\n",
              " 'Canada',\n",
              " 'd',\n",
              " '�',\n",
              " '�',\n",
              " 'cortiqu',\n",
              " '�',\n",
              " '�',\n",
              " 'e',\n",
              " 'en',\n",
              " '5',\n",
              " 'questions',\n",
              " 'https://t.co/f4utO5A7ZF',\n",
              " \"L'immigration\",\n",
              " 'irr',\n",
              " '�',\n",
              " '�',\n",
              " 'guli',\n",
              " '�',\n",
              " '�',\n",
              " 're',\n",
              " 'au',\n",
              " 'Canada',\n",
              " 'd',\n",
              " '�',\n",
              " '�',\n",
              " 'cortiqu',\n",
              " '�',\n",
              " '�',\n",
              " 'e',\n",
              " 'en',\n",
              " '5',\n",
              " 'questions',\n",
              " '-',\n",
              " 'https://t.co/UiBsEZOqas',\n",
              " 'https://t.co/j77dEvjoiX',\n",
              " 'https://t.co/XXDeIG7Dbu',\n",
              " 'Will',\n",
              " 'Media',\n",
              " 'ask',\n",
              " 'the',\n",
              " 'Liberals',\n",
              " 'if',\n",
              " 'they',\n",
              " 'actually',\n",
              " 'have',\n",
              " 'a',\n",
              " 'solid',\n",
              " 'plan',\n",
              " 'for',\n",
              " 'Canada',\n",
              " '_',\n",
              " '�',\n",
              " '�',\n",
              " '_',\n",
              " '�',\n",
              " '_',\n",
              " '?',\n",
              " '?',\n",
              " 'From',\n",
              " 'my',\n",
              " 'view',\n",
              " '-',\n",
              " '-',\n",
              " 'immigration',\n",
              " 'out',\n",
              " 'of',\n",
              " 'C',\n",
              " '�',\n",
              " '�',\n",
              " '_',\n",
              " 'https://t.co/YAgwmZ8ECp',\n",
              " 'Dan',\n",
              " 'Murray',\n",
              " 'of',\n",
              " '�',\n",
              " '�',\n",
              " 'Immigration',\n",
              " 'Watch',\n",
              " 'Canada',\n",
              " 'is',\n",
              " 'xenophobic',\n",
              " 'racist',\n",
              " 'fear-mongering',\n",
              " 'liar',\n",
              " '#racism',\n",
              " '#canada',\n",
              " '#cdnpoli',\n",
              " '#hatecrime',\n",
              " '�',\n",
              " '�',\n",
              " '_',\n",
              " 'https://t.co/kwZ3csvYxM',\n",
              " 'Le',\n",
              " 'Canada',\n",
              " 'lance',\n",
              " 'une',\n",
              " 'vaste',\n",
              " 'campagne',\n",
              " \"d'immigration\",\n",
              " 'pour',\n",
              " 'faire',\n",
              " 'face',\n",
              " '�',\n",
              " '�',\n",
              " 'son',\n",
              " 'besoin',\n",
              " 'de',\n",
              " 'main',\n",
              " 'd',\n",
              " \"'\",\n",
              " '�',\n",
              " '�',\n",
              " 'uvre',\n",
              " 'https://t.co/kXdfMGTZzN',\n",
              " 'L',\n",
              " '�',\n",
              " '�',\n",
              " '#immigration',\n",
              " 'irr',\n",
              " '�',\n",
              " '�',\n",
              " 'guli',\n",
              " '�',\n",
              " '�',\n",
              " 're',\n",
              " 'au',\n",
              " '#Canada',\n",
              " 'd',\n",
              " '�',\n",
              " '�',\n",
              " 'cortiqu',\n",
              " '�',\n",
              " '�',\n",
              " 'e',\n",
              " 'en',\n",
              " '5',\n",
              " '�',\n",
              " '�',\n",
              " 'questions',\n",
              " 'https://t.co/s3hu1OKKIG',\n",
              " \"I've\",\n",
              " 'read',\n",
              " 'the',\n",
              " 'Immigration',\n",
              " 'laws',\n",
              " 'of',\n",
              " 'Canada',\n",
              " 'much',\n",
              " 'stricter',\n",
              " 'than',\n",
              " 'the',\n",
              " 'US',\n",
              " 'Canada',\n",
              " 'Immigration',\n",
              " 'Website',\n",
              " 'Traffic',\n",
              " 'Surges',\n",
              " 'And',\n",
              " 'Crashes',\n",
              " 'In',\n",
              " 'Wake',\n",
              " 'Of',\n",
              " 'Trump',\n",
              " '#fasttraffic',\n",
              " ',',\n",
              " '#sitetraffic',\n",
              " ',',\n",
              " '#website',\n",
              " ',',\n",
              " '#traffic',\n",
              " 'https://t.co/zRlJ26jnkC',\n",
              " 'Mr',\n",
              " 'Know-all',\n",
              " 'of',\n",
              " 'Canada',\n",
              " 'Immigration',\n",
              " 'https://t.co/wTQK4QDiKI',\n",
              " 'Move',\n",
              " 'to',\n",
              " 'Canada',\n",
              " 'Oh',\n",
              " ',',\n",
              " 'immigration',\n",
              " 'rules',\n",
              " ',',\n",
              " 'you',\n",
              " \"can't\",\n",
              " '...',\n",
              " 'https://t.co/5LIEVHO7A4',\n",
              " '#OnThisDay',\n",
              " 'Annette',\n",
              " 'Toft',\n",
              " 'becomes',\n",
              " \"Canada's\",\n",
              " '2',\n",
              " 'millionth',\n",
              " 'immigrant',\n",
              " 'since',\n",
              " '1945',\n",
              " '.',\n",
              " 'Do',\n",
              " 'you',\n",
              " 'know',\n",
              " 'your',\n",
              " \"family's\",\n",
              " 'immigration',\n",
              " 'st',\n",
              " '�',\n",
              " '�',\n",
              " '_',\n",
              " 'https://t.co/UvRuw8eR1b',\n",
              " '.',\n",
              " 'profiles',\n",
              " \"Canada's\",\n",
              " 'open',\n",
              " 'immigration',\n",
              " 'policies',\n",
              " '&',\n",
              " 'how',\n",
              " 'they',\n",
              " 'contribute',\n",
              " 'to',\n",
              " 'our',\n",
              " 'economic',\n",
              " 'success',\n",
              " ':',\n",
              " '�',\n",
              " '�',\n",
              " '_',\n",
              " 'https://t.co/4K84EE8Y63',\n",
              " 'Hundreds',\n",
              " 'may',\n",
              " 'lose',\n",
              " 'Canadian',\n",
              " 'citizenship',\n",
              " ',',\n",
              " 'resident',\n",
              " 'status',\n",
              " 'because',\n",
              " 'of',\n",
              " 'one',\n",
              " 'corrupt',\n",
              " 'immigration',\n",
              " 'consultant',\n",
              " 'https://t.co/x2IfO0EXI2',\n",
              " 'Immigration',\n",
              " 'for',\n",
              " 'canada',\n",
              " 'without',\n",
              " 'india',\n",
              " ':',\n",
              " 'an',\n",
              " 'compassionate',\n",
              " 'handle',\n",
              " ':',\n",
              " 'deyFy',\n",
              " '\"',\n",
              " '#Jamaican',\n",
              " '#immigrants',\n",
              " '#Canada',\n",
              " 'https://t.co/vcmfYGadR5',\n",
              " '#statistics',\n",
              " '#immigration',\n",
              " '\"',\n",
              " 'Mexican',\n",
              " 'visa',\n",
              " 'lift',\n",
              " 'expected',\n",
              " 'to',\n",
              " 'cost',\n",
              " 'Canada',\n",
              " '$',\n",
              " '262M',\n",
              " 'over',\n",
              " 'a',\n",
              " 'decade',\n",
              " 'https://t.co/9i72fRhtij',\n",
              " 'Are',\n",
              " 'people',\n",
              " 'still',\n",
              " 'moving',\n",
              " 'to',\n",
              " '#Canada',\n",
              " '?',\n",
              " '?',\n",
              " '?',\n",
              " 'Oh',\n",
              " \"that's\",\n",
              " 'right',\n",
              " ',',\n",
              " 'they',\n",
              " 'have',\n",
              " 'real',\n",
              " 'immigration',\n",
              " 'laws',\n",
              " 'and',\n",
              " \"it's\",\n",
              " '�',\n",
              " '�',\n",
              " '_',\n",
              " 'https://t.co/0C5OBfmxLG',\n",
              " 'Here',\n",
              " 'are',\n",
              " 'more',\n",
              " 'details',\n",
              " 'on',\n",
              " 'the',\n",
              " 'Richmond',\n",
              " ',',\n",
              " 'B',\n",
              " '.',\n",
              " 'C',\n",
              " '.',\n",
              " 'Immigration',\n",
              " 'Consultant',\n",
              " 'Sunny',\n",
              " 'Wang',\n",
              " 'who',\n",
              " 'was',\n",
              " 'sentenced',\n",
              " 'to',\n",
              " '7',\n",
              " 'years',\n",
              " 'in',\n",
              " '...',\n",
              " 'https://t.co/YXH5W53srO',\n",
              " 'I',\n",
              " 'added',\n",
              " 'a',\n",
              " 'video',\n",
              " 'to',\n",
              " 'a',\n",
              " 'playlist',\n",
              " 'https://t.co/CnEyWN40x3',\n",
              " 'Funny',\n",
              " 'Talking',\n",
              " 'of',\n",
              " 'Haryanavi',\n",
              " 'Jat',\n",
              " 'with',\n",
              " 'Canada',\n",
              " 'Immigration',\n",
              " 'Girl',\n",
              " 'Agent',\n",
              " 'Mexicans',\n",
              " 'Can',\n",
              " 'Now',\n",
              " 'Travel',\n",
              " 'Visa-Free',\n",
              " 'To',\n",
              " 'Canada',\n",
              " 'https://t.co/Ec3XHORO2s',\n",
              " 'https://t.co/RQRr5nebcG',\n",
              " 'L',\n",
              " '�',\n",
              " '�',\n",
              " 'immigration',\n",
              " 'irr',\n",
              " '�',\n",
              " '�',\n",
              " 'guli',\n",
              " '�',\n",
              " '�',\n",
              " 're',\n",
              " 'au',\n",
              " 'Canada',\n",
              " 'd',\n",
              " '�',\n",
              " '�',\n",
              " 'cortiqu',\n",
              " '�',\n",
              " '�',\n",
              " 'e',\n",
              " 'en',\n",
              " '5',\n",
              " '�',\n",
              " '�',\n",
              " 'questions',\n",
              " 'https://t.co/DkpuKyWmaK',\n",
              " 'Hes',\n",
              " 'the',\n",
              " 'POS',\n",
              " 'that',\n",
              " 'ramped',\n",
              " 'up',\n",
              " 'immigration',\n",
              " 'for',\n",
              " 'Canada',\n",
              " ',',\n",
              " 'among',\n",
              " 'other',\n",
              " 'globalist',\n",
              " 'policies',\n",
              " '.',\n",
              " 'Canada',\n",
              " 'lifted',\n",
              " 'visa',\n",
              " 'requirements',\n",
              " 'to',\n",
              " 'Mexico',\n",
              " 'as',\n",
              " 'of',\n",
              " 'Dec',\n",
              " '1',\n",
              " ',',\n",
              " '2016',\n",
              " '.',\n",
              " 'Thoughts',\n",
              " '?',\n",
              " '#visa',\n",
              " '#immigration',\n",
              " 'people',\n",
              " 'Keep',\n",
              " 'praising',\n",
              " 'Canada',\n",
              " 'and',\n",
              " 'Canada',\n",
              " 'has',\n",
              " 'way',\n",
              " 'stricter',\n",
              " 'immigration',\n",
              " 'laws',\n",
              " 'then',\n",
              " 'us',\n",
              " 'they',\n",
              " 'willl',\n",
              " 'boot',\n",
              " 'your',\n",
              " 'liberal',\n",
              " 'American',\n",
              " 'ass']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN_o3qCVYXWX"
      },
      "source": [
        "data = \"#cdnpoli #LPC #CPCLDR��_ https://t.co/ZOZOSe1CqQ\""
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "193rWoDShhwp"
      },
      "source": [
        "compare_list = ['#cdnpoli',\n",
        "               '#LPC #CPCLDR��_',\n",
        "               'https://t.co/ZOZOSe1CqQ']"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fik2ezyjYVzy",
        "outputId": "fd38e1e1-3840-4c26-e804-294750febf6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "punct_tokenizer = WordPunctTokenizer()\n",
        "punct_tokens = []\n",
        "for sent in compare_list:\n",
        "    print(punct_tokenizer.tokenize(sent))\n",
        "    punct_tokens.append(punct_tokenizer.tokenize(sent))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['#', 'cdnpoli']\n",
            "['#', 'LPC', '#', 'CPCLDR', '��', '_']\n",
            "['https', '://', 't', '.', 'co', '/', 'ZOZOSe1CqQ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWCmLuTriSkd",
        "outputId": "8987d691-e6d8-4c0b-f045-d8bfb571f70f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "match_tokenizer = RegexpTokenizer(\"[\\w']+\")\n",
        "match_tokens = []\n",
        "for sent in compare_list:   \n",
        "    print(match_tokenizer.tokenize(sent))\n",
        "    match_tokens.append(match_tokenizer.tokenize(sent))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['cdnpoli']\n",
            "['LPC', 'CPCLDR', '_']\n",
            "['https', 't', 'co', 'ZOZOSe1CqQ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2oJqGD4iZpV",
        "outputId": "e6bc658d-ee71-4a28-b246-64f19244ebaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "space_tokenizer = RegexpTokenizer(\"\\s+\", gaps=True)\n",
        "space_tokens = []\n",
        "for sent in compare_list:\n",
        "    \n",
        "    print(space_tokenizer.tokenize(sent))\n",
        "    space_tokens.append(space_tokenizer.tokenize(sent))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['#cdnpoli']\n",
            "['#LPC', '#CPCLDR��_']\n",
            "['https://t.co/ZOZOSe1CqQ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zo84bbDALqS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zzt4u1nNifio",
        "outputId": "d687850a-5dcd-41ea-9a23-b885fb8ab410",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.tokenize import TweetTokenizer\n",
        "tweet_tokenizer = TweetTokenizer()\n",
        "tweet_tokens = []\n",
        "for sent in compare_list:\n",
        "    print(tweet_tokenizer.tokenize(sent))\n",
        "    tweet_tokens.append(tweet_tokenizer.tokenize(sent))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['#cdnpoli']\n",
            "['#LPC', '#CPCLDR', '�', '�', '_']\n",
            "['https://t.co/ZOZOSe1CqQ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGa53O9qoDoC"
      },
      "source": [
        "from nltk.tag.stanford import StanfordNERTagger\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-PntgkkoFVE",
        "outputId": "1f09063f-9e14-4007-88e5-55791401e426",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget 'https://nlp.stanford.edu/software/stanford-ner-2018-10-16.zip'\n",
        "!unzip stanford-ner-2018-10-16.zip"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-01 07:05:58--  https://nlp.stanford.edu/software/stanford-ner-2018-10-16.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 180358328 (172M) [application/zip]\n",
            "Saving to: ‘stanford-ner-2018-10-16.zip’\n",
            "\n",
            "stanford-ner-2018-1 100%[===================>] 172.00M  4.55MB/s    in 39s     \n",
            "\n",
            "2020-11-01 07:06:38 (4.36 MB/s) - ‘stanford-ner-2018-10-16.zip’ saved [180358328/180358328]\n",
            "\n",
            "Archive:  stanford-ner-2018-10-16.zip\n",
            "   creating: stanford-ner-2018-10-16/\n",
            "  inflating: stanford-ner-2018-10-16/README.txt  \n",
            "  inflating: stanford-ner-2018-10-16/ner-gui.bat  \n",
            "  inflating: stanford-ner-2018-10-16/build.xml  \n",
            "  inflating: stanford-ner-2018-10-16/stanford-ner.jar  \n",
            "  inflating: stanford-ner-2018-10-16/sample-conll-file.txt  \n",
            "  inflating: stanford-ner-2018-10-16/sample.ner.txt  \n",
            "  inflating: stanford-ner-2018-10-16/stanford-ner-3.9.2-sources.jar  \n",
            "   creating: stanford-ner-2018-10-16/lib/\n",
            "  inflating: stanford-ner-2018-10-16/lib/joda-time.jar  \n",
            "  inflating: stanford-ner-2018-10-16/lib/stanford-ner-resources.jar  \n",
            "  inflating: stanford-ner-2018-10-16/lib/jollyday-0.4.9.jar  \n",
            "  inflating: stanford-ner-2018-10-16/ner-gui.command  \n",
            "  inflating: stanford-ner-2018-10-16/ner.sh  \n",
            "  inflating: stanford-ner-2018-10-16/stanford-ner-3.9.2.jar  \n",
            "  inflating: stanford-ner-2018-10-16/NERDemo.java  \n",
            "  inflating: stanford-ner-2018-10-16/stanford-ner-3.9.2-javadoc.jar  \n",
            "  inflating: stanford-ner-2018-10-16/ner.bat  \n",
            "   creating: stanford-ner-2018-10-16/classifiers/\n",
            "  inflating: stanford-ner-2018-10-16/classifiers/english.conll.4class.distsim.prop  \n",
            "  inflating: stanford-ner-2018-10-16/classifiers/example.serialized.ncc.ncc.ser.gz  \n",
            "  inflating: stanford-ner-2018-10-16/classifiers/english.muc.7class.distsim.crf.ser.gz  \n",
            "  inflating: stanford-ner-2018-10-16/classifiers/english.conll.4class.distsim.crf.ser.gz  \n",
            "  inflating: stanford-ner-2018-10-16/classifiers/english.muc.7class.distsim.prop  \n",
            "  inflating: stanford-ner-2018-10-16/classifiers/english.all.3class.distsim.prop  \n",
            "  inflating: stanford-ner-2018-10-16/classifiers/example.serialized.ncc.prop  \n",
            "  inflating: stanford-ner-2018-10-16/classifiers/english.all.3class.distsim.crf.ser.gz  \n",
            "  inflating: stanford-ner-2018-10-16/sample.txt  \n",
            "  inflating: stanford-ner-2018-10-16/sample-w-time.txt  \n",
            "  inflating: stanford-ner-2018-10-16/ner-gui.sh  \n",
            "  inflating: stanford-ner-2018-10-16/LICENSE.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7T0HMymoIvX",
        "outputId": "4e5c3b95-65d7-4163-b814-0258f11a15aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLuCDjRPoWdW",
        "outputId": "ed2455f2-9786-45dd-da7e-a48157d06c6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "st = StanfordNERTagger('/content/stanford-ner-2018-10-16/classifiers/english.all.3class.distsim.crf.ser.gz',\n",
        "                       '/content/stanford-ner-2018-10-16/stanford-ner.jar',\n",
        "                       encoding='utf-8')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/tag/stanford.py:183: DeprecationWarning: \n",
            "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
            "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
            "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ibi-Nub8oa7u"
      },
      "source": [
        "research_data = open('/content/research_paper.txt', 'r')\n",
        "file_content = research_data.read()"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li571OkLqYtE"
      },
      "source": [
        "tokenized_text = word_tokenize(file_content)\n",
        "classified_text = st.tag(tokenized_text)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrB-_hG-qjFm",
        "outputId": "4d6e6405-e095-40e2-ec8e-9b09dc2eb324",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "classified_text"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Neural', 'O'),\n",
              " ('network', 'O'),\n",
              " ('models', 'O'),\n",
              " ('have', 'O'),\n",
              " ('shown', 'O'),\n",
              " ('their', 'O'),\n",
              " ('promising', 'O'),\n",
              " ('opportunities', 'O'),\n",
              " ('for', 'O'),\n",
              " ('multi-task', 'O'),\n",
              " ('learning', 'O'),\n",
              " (',', 'O'),\n",
              " ('which', 'O'),\n",
              " ('focus', 'O'),\n",
              " ('on', 'O'),\n",
              " ('learning', 'O'),\n",
              " ('the', 'O'),\n",
              " ('shared', 'O'),\n",
              " ('layers', 'O'),\n",
              " ('to', 'O'),\n",
              " ('extract', 'O'),\n",
              " ('the', 'O'),\n",
              " ('common', 'O'),\n",
              " ('and', 'O'),\n",
              " ('task-invariant', 'O'),\n",
              " ('features', 'O'),\n",
              " ('.', 'O'),\n",
              " ('However', 'O'),\n",
              " (',', 'O'),\n",
              " ('in', 'O'),\n",
              " ('most', 'O'),\n",
              " ('existing', 'O'),\n",
              " ('approaches', 'O'),\n",
              " (',', 'O'),\n",
              " ('the', 'O'),\n",
              " ('extracted', 'O'),\n",
              " ('shared', 'O'),\n",
              " ('features', 'O'),\n",
              " ('are', 'O'),\n",
              " ('prone', 'O'),\n",
              " ('to', 'O'),\n",
              " ('be', 'O'),\n",
              " ('contaminated', 'O'),\n",
              " ('by', 'O'),\n",
              " ('task-specific', 'O'),\n",
              " ('features', 'O'),\n",
              " ('or', 'O'),\n",
              " ('the', 'O'),\n",
              " ('noise', 'O'),\n",
              " ('brought', 'O'),\n",
              " ('by', 'O'),\n",
              " ('other', 'O'),\n",
              " ('tasks', 'O'),\n",
              " ('.', 'O'),\n",
              " ('In', 'O'),\n",
              " ('this', 'O'),\n",
              " ('paper', 'O'),\n",
              " (',', 'O'),\n",
              " ('we', 'O'),\n",
              " ('propose', 'O'),\n",
              " ('an', 'O'),\n",
              " ('adversarial', 'O'),\n",
              " ('multi-task', 'O'),\n",
              " ('learning', 'O'),\n",
              " ('framework', 'O'),\n",
              " (',', 'O'),\n",
              " ('alleviating', 'O'),\n",
              " ('the', 'O'),\n",
              " ('shared', 'O'),\n",
              " ('and', 'O'),\n",
              " ('private', 'O'),\n",
              " ('latent', 'O'),\n",
              " ('feature', 'O'),\n",
              " ('spaces', 'O'),\n",
              " ('from', 'O'),\n",
              " ('interfering', 'O'),\n",
              " ('with', 'O'),\n",
              " ('each', 'O'),\n",
              " ('other', 'O'),\n",
              " ('.', 'O'),\n",
              " ('We', 'O'),\n",
              " ('conduct', 'O'),\n",
              " ('extensive', 'O'),\n",
              " ('experiments', 'O'),\n",
              " ('on', 'O'),\n",
              " ('16', 'O'),\n",
              " ('different', 'O'),\n",
              " ('text', 'O'),\n",
              " ('classification', 'O'),\n",
              " ('tasks', 'O'),\n",
              " (',', 'O'),\n",
              " ('which', 'O'),\n",
              " ('demonstrates', 'O'),\n",
              " ('the', 'O'),\n",
              " ('benefits', 'O'),\n",
              " ('of', 'O'),\n",
              " ('our', 'O'),\n",
              " ('approach', 'O'),\n",
              " ('.', 'O'),\n",
              " ('Besides', 'O'),\n",
              " (',', 'O'),\n",
              " ('we', 'O'),\n",
              " ('show', 'O'),\n",
              " ('that', 'O'),\n",
              " ('the', 'O'),\n",
              " ('shared', 'O'),\n",
              " ('knowledge', 'O'),\n",
              " ('learned', 'O'),\n",
              " ('by', 'O'),\n",
              " ('our', 'O'),\n",
              " ('proposed', 'O'),\n",
              " ('model', 'O'),\n",
              " ('can', 'O'),\n",
              " ('be', 'O'),\n",
              " ('regarded', 'O'),\n",
              " ('as', 'O'),\n",
              " ('off-the-shelf', 'O'),\n",
              " ('knowledge', 'O'),\n",
              " ('and', 'O'),\n",
              " ('easily', 'O'),\n",
              " ('transferred', 'O'),\n",
              " ('to', 'O'),\n",
              " ('new', 'O'),\n",
              " ('tasks', 'O'),\n",
              " ('.', 'O'),\n",
              " ('Multi-task', 'O'),\n",
              " ('learning', 'O'),\n",
              " ('is', 'O'),\n",
              " ('an', 'O'),\n",
              " ('effective', 'O'),\n",
              " ('approach', 'O'),\n",
              " ('to', 'O'),\n",
              " ('improve', 'O'),\n",
              " ('the', 'O'),\n",
              " ('performance', 'O'),\n",
              " ('of', 'O'),\n",
              " ('a', 'O'),\n",
              " ('single', 'O'),\n",
              " ('task', 'O'),\n",
              " ('with', 'O'),\n",
              " ('the', 'O'),\n",
              " ('help', 'O'),\n",
              " ('of', 'O'),\n",
              " ('other', 'O'),\n",
              " ('related', 'O'),\n",
              " ('tasks', 'O'),\n",
              " ('.', 'O'),\n",
              " ('Recently', 'O'),\n",
              " (',', 'O'),\n",
              " ('neural-based', 'O'),\n",
              " ('models', 'O'),\n",
              " ('for', 'O'),\n",
              " ('multi-task', 'O'),\n",
              " ('learning', 'O'),\n",
              " ('have', 'O'),\n",
              " ('become', 'O'),\n",
              " ('very', 'O'),\n",
              " ('popular', 'O'),\n",
              " (',', 'O'),\n",
              " ('ranging', 'O'),\n",
              " ('from', 'O'),\n",
              " ('computer', 'O'),\n",
              " ('vision', 'O'),\n",
              " ('(', 'O'),\n",
              " ('Misra', 'O'),\n",
              " ('et', 'O'),\n",
              " ('al.', 'O'),\n",
              " (',', 'O'),\n",
              " ('2016', 'O'),\n",
              " (';', 'O'),\n",
              " ('Zhang', 'PERSON'),\n",
              " ('et', 'O'),\n",
              " ('al.', 'O'),\n",
              " (',', 'O'),\n",
              " ('2014', 'O'),\n",
              " (')', 'O'),\n",
              " ('to', 'O'),\n",
              " ('natural', 'O'),\n",
              " ('language', 'O'),\n",
              " ('processing', 'O'),\n",
              " ('(', 'O'),\n",
              " ('Collobert', 'O'),\n",
              " ('andWeston', 'O'),\n",
              " (',', 'O'),\n",
              " ('2008', 'O'),\n",
              " (';', 'O'),\n",
              " ('Luong', 'PERSON'),\n",
              " ('et', 'O'),\n",
              " ('al.', 'O'),\n",
              " (',', 'O'),\n",
              " ('2015', 'O'),\n",
              " (')', 'O'),\n",
              " (',', 'O'),\n",
              " ('since', 'O'),\n",
              " ('they', 'O'),\n",
              " ('provide', 'O'),\n",
              " ('a', 'O'),\n",
              " ('convenient', 'O'),\n",
              " ('way', 'O'),\n",
              " ('of', 'O'),\n",
              " ('combining', 'O'),\n",
              " ('information', 'O'),\n",
              " ('from', 'O'),\n",
              " ('multiple', 'O'),\n",
              " ('tasks', 'O'),\n",
              " ('.', 'O'),\n",
              " ('However', 'O'),\n",
              " (',', 'O'),\n",
              " ('most', 'O'),\n",
              " ('existing', 'O'),\n",
              " ('work', 'O'),\n",
              " ('on', 'O'),\n",
              " ('multi-task', 'O'),\n",
              " ('learning', 'O'),\n",
              " ('(', 'O'),\n",
              " ('Liu', 'PERSON'),\n",
              " ('et', 'O'),\n",
              " ('al.', 'O'),\n",
              " (',', 'O'),\n",
              " ('2016c', 'O'),\n",
              " (',', 'O'),\n",
              " ('b', 'O'),\n",
              " (')', 'O'),\n",
              " ('attempts', 'O'),\n",
              " ('to', 'O'),\n",
              " ('divide', 'O'),\n",
              " ('the', 'O'),\n",
              " ('features', 'O'),\n",
              " ('of', 'O'),\n",
              " ('different', 'O'),\n",
              " ('tasks', 'O'),\n",
              " ('into', 'O'),\n",
              " ('private', 'O'),\n",
              " ('and', 'O'),\n",
              " ('shared', 'O'),\n",
              " ('spaces', 'O'),\n",
              " (',', 'O'),\n",
              " ('merely', 'O'),\n",
              " ('based', 'O'),\n",
              " ('on', 'O'),\n",
              " ('whether', 'O'),\n",
              " ('parameters', 'O'),\n",
              " ('of', 'O'),\n",
              " ('some', 'O'),\n",
              " ('components', 'O'),\n",
              " ('should', 'O'),\n",
              " ('be', 'O'),\n",
              " ('shared', 'O'),\n",
              " ('.', 'O'),\n",
              " ('As', 'O'),\n",
              " ('shown', 'O'),\n",
              " ('in', 'O'),\n",
              " ('Figure', 'O'),\n",
              " ('1-', 'O'),\n",
              " ('(', 'O'),\n",
              " ('a', 'O'),\n",
              " (')', 'O'),\n",
              " (',', 'O'),\n",
              " ('the', 'O'),\n",
              " ('general', 'O'),\n",
              " ('shared-private', 'O'),\n",
              " ('model', 'O'),\n",
              " ('introduces', 'O'),\n",
              " ('two', 'O'),\n",
              " ('feature', 'O'),\n",
              " ('spaces', 'O'),\n",
              " ('for', 'O'),\n",
              " ('any', 'O'),\n",
              " ('task', 'O'),\n",
              " (':', 'O'),\n",
              " ('one', 'O'),\n",
              " ('is', 'O'),\n",
              " ('used', 'O'),\n",
              " ('to', 'O'),\n",
              " ('store', 'O'),\n",
              " ('task-dependent', 'O'),\n",
              " ('features', 'O'),\n",
              " (',', 'O'),\n",
              " ('the', 'O'),\n",
              " ('other', 'O'),\n",
              " ('is', 'O'),\n",
              " ('used', 'O'),\n",
              " ('to', 'O'),\n",
              " ('capture', 'O'),\n",
              " ('shared', 'O'),\n",
              " ('features', 'O'),\n",
              " ('.', 'O'),\n",
              " ('The', 'O'),\n",
              " ('major', 'O'),\n",
              " ('limitation', 'O'),\n",
              " ('of', 'O'),\n",
              " ('this', 'O'),\n",
              " ('framework', 'O'),\n",
              " ('is', 'O'),\n",
              " ('that', 'O'),\n",
              " ('the', 'O'),\n",
              " ('shared', 'O'),\n",
              " ('feature', 'O'),\n",
              " ('space', 'O'),\n",
              " ('could', 'O'),\n",
              " ('contain', 'O'),\n",
              " ('some', 'O'),\n",
              " ('unnecessary', 'O'),\n",
              " ('task-specific', 'O'),\n",
              " ('features', 'O'),\n",
              " (',', 'O'),\n",
              " ('while', 'O'),\n",
              " ('some', 'O'),\n",
              " ('sharable', 'O'),\n",
              " ('features', 'O'),\n",
              " ('could', 'O'),\n",
              " ('also', 'O'),\n",
              " ('be', 'O'),\n",
              " ('mixed', 'O'),\n",
              " ('in', 'O'),\n",
              " ('private', 'O'),\n",
              " ('space', 'O'),\n",
              " (',', 'O'),\n",
              " ('suffering', 'O'),\n",
              " ('from', 'O'),\n",
              " ('feature', 'O'),\n",
              " ('redundancy', 'O'),\n",
              " ('.', 'O'),\n",
              " ('Taking', 'O'),\n",
              " ('the', 'O'),\n",
              " ('following', 'O'),\n",
              " ('two', 'O'),\n",
              " ('sentences', 'O'),\n",
              " ('as', 'O'),\n",
              " ('examples', 'O'),\n",
              " (',', 'O'),\n",
              " ('which', 'O'),\n",
              " ('are', 'O'),\n",
              " ('extracted', 'O'),\n",
              " ('from', 'O'),\n",
              " ('two', 'O'),\n",
              " ('different', 'O'),\n",
              " ('sentiment', 'O'),\n",
              " ('classification', 'O'),\n",
              " ('tasks', 'O'),\n",
              " (':', 'O'),\n",
              " ('Movie', 'O'),\n",
              " ('reviews', 'O'),\n",
              " ('and', 'O'),\n",
              " ('Baby', 'O'),\n",
              " ('products', 'O'),\n",
              " ('reviews', 'O'),\n",
              " ('.', 'O'),\n",
              " ('The', 'O'),\n",
              " ('infantile', 'O'),\n",
              " ('cart', 'O'),\n",
              " ('is', 'O'),\n",
              " ('simple', 'O'),\n",
              " ('and', 'O'),\n",
              " ('easy', 'O'),\n",
              " ('to', 'O'),\n",
              " ('use', 'O'),\n",
              " ('.', 'O'),\n",
              " ('This', 'O'),\n",
              " ('kind', 'O'),\n",
              " ('of', 'O'),\n",
              " ('humour', 'O'),\n",
              " ('is', 'O'),\n",
              " ('infantile', 'O'),\n",
              " ('and', 'O'),\n",
              " ('boring', 'O'),\n",
              " ('.', 'O'),\n",
              " ('The', 'O'),\n",
              " ('word', 'O'),\n",
              " ('�infantile�', 'O'),\n",
              " ('indicates', 'O'),\n",
              " ('negative', 'O'),\n",
              " ('sentiment', 'O'),\n",
              " ('in', 'O'),\n",
              " ('Movie', 'O'),\n",
              " ('task', 'O'),\n",
              " ('while', 'O'),\n",
              " ('it', 'O'),\n",
              " ('is', 'O'),\n",
              " ('neutral', 'O'),\n",
              " ('in', 'O'),\n",
              " ('Baby', 'O'),\n",
              " ('task', 'O'),\n",
              " ('.', 'O'),\n",
              " ('However', 'O'),\n",
              " (',', 'O'),\n",
              " ('the', 'O'),\n",
              " ('general', 'O'),\n",
              " ('shared-private', 'O'),\n",
              " ('model', 'O'),\n",
              " ('could', 'O'),\n",
              " ('place', 'O'),\n",
              " ('the', 'O'),\n",
              " ('task-specific', 'O'),\n",
              " ('word', 'O'),\n",
              " ('�infantile�', 'O'),\n",
              " ('in', 'O'),\n",
              " ('a', 'O'),\n",
              " ('shared', 'O'),\n",
              " ('space', 'O'),\n",
              " (',', 'O'),\n",
              " ('leaving', 'O'),\n",
              " ('potential', 'O'),\n",
              " ('hazards', 'O'),\n",
              " ('for', 'O'),\n",
              " ('other', 'O'),\n",
              " ('tasks', 'O'),\n",
              " ('.', 'O'),\n",
              " ('Additionally', 'O'),\n",
              " (',', 'O'),\n",
              " ('the', 'O'),\n",
              " ('capacity', 'O'),\n",
              " ('of', 'O'),\n",
              " ('shared', 'O'),\n",
              " ('space', 'O'),\n",
              " ('could', 'O'),\n",
              " ('also', 'O'),\n",
              " ('be', 'O'),\n",
              " ('wasted', 'O'),\n",
              " ('by', 'O'),\n",
              " ('some', 'O'),\n",
              " ('unnecessary', 'O'),\n",
              " ('features', 'O'),\n",
              " ('.', 'O'),\n",
              " ('To', 'O'),\n",
              " ('address', 'O'),\n",
              " ('this', 'O'),\n",
              " ('problem', 'O'),\n",
              " (',', 'O'),\n",
              " ('in', 'O'),\n",
              " ('this', 'O'),\n",
              " ('paper', 'O'),\n",
              " ('we', 'O'),\n",
              " ('propose', 'O'),\n",
              " ('an', 'O'),\n",
              " ('adversarial', 'O'),\n",
              " ('multi-task', 'O'),\n",
              " ('framework', 'O'),\n",
              " (',', 'O'),\n",
              " ('in', 'O'),\n",
              " ('which', 'O'),\n",
              " ('the', 'O'),\n",
              " ('shared', 'O'),\n",
              " ('and', 'O'),\n",
              " ('private', 'O'),\n",
              " ('feature', 'O'),\n",
              " ('spaces', 'O'),\n",
              " ('are', 'O'),\n",
              " ('in', 'O'),\n",
              " ('herently', 'O'),\n",
              " ('disjoint', 'O'),\n",
              " ('by', 'O'),\n",
              " ('introducing', 'O'),\n",
              " ('orthogonality', 'O'),\n",
              " ('constraints.Specifically', 'O'),\n",
              " (',', 'O'),\n",
              " ('we', 'O'),\n",
              " ('design', 'O'),\n",
              " ('a', 'O'),\n",
              " ('generic', 'O'),\n",
              " ('shared', 'O'),\n",
              " ('private', 'O'),\n",
              " ('learning', 'O'),\n",
              " ('framework', 'O'),\n",
              " ('to', 'O'),\n",
              " ('model', 'O'),\n",
              " ('the', 'O'),\n",
              " ('text', 'O'),\n",
              " ('sequence', 'O'),\n",
              " ('.', 'O')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLYsoBTb8-EF",
        "outputId": "c588fe82-ee05-4701-cc39-3390054c06c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "feedback_data = open('/content/feedback.txt', 'r')\n",
        "file_content = feedback_data.read()\n",
        "data = BeautifulSoup(file_content).get_text()\n",
        "tokens = nltk.word_tokenize(data)\n",
        "print(tokens)\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Honestly', 'last', 'seven', 'lectures', 'are', 'good', '.', 'Lectures', 'are', 'understandable', '.', 'Lecture', 'slides', 'are', 'very', 'useful', 'to', 'self-study', 'also', '.', 'The', 'given', 'opportunity', 'to', 'ask', 'questions', 'from', 'the', 'lecturer', 'is', 'appreciative', '.', '``', 'Good', ':', ')', 'please', 'do', 'recap', 'at', 'class', 'starting', 'it', \"'s\", 'better', 'for', 'us', '.', 'sometimes', 'teaching', 'speed', 'is', 'very', 'high', '.', 'Thanks', '!', ':', ')', '``', 'The', 'lectures', 'are', 'good..but', 'a', 'bit', 'speed.A', 'in', 'class', 'working', 'activity', 'is', 'a', 'must', 'one.So', 'please', 'take', 'another', 'hour', 'in', 'thursdays', 'madame.', \"''\", 'We', 'can', 'hear', 'your', 'voice', 'clearly', 'and', 'can', 'understand', 'the', 'things', 'you', 'teach', '.', 'Presentation', 'slides', 'also', 'good', 'source', 'to', 'refer', '.', 'lf', 'you', 'can', 'do', 'more', 'example', 'questions', 'within', 'the', 'classroom', 'and', 'it', 'will', 'help', 'us', 'to', 'understand', 'the', 'principles', 'well.', \"''\", 'Lectures', 'was', 'well', 'structured', 'and', 'well', 'organized', '.', 'It', 'was', 'easy', 'to', 'understand', '.', 'Lecture', 'slides', 'and', 'labs', 'were', 'also', 'well', 'organized', '.', 'Lectures', 'were', 'good', '.', 'understandable', '.', 'The', 'lecture', 'slides', 'were', 'well', 'organized', 'and', 'the', 'examples', 'done', 'in', 'the', 'class', 'helped', 'a', 'lot', 'to', 'learn', 'this', 'new', 'language', 'and', 'also', 'the', 'principles', 'of', 'OOP', '.', 'Motivated', 'to', 'well', '.', 'Would', 'have', 'been', 'better', 'if', 'we', 'discussed', 'more', 'about', 'the', 'solutions', 'of', 'coding', 'exercisers', '.', 'I', 'think', 'i', 'learned', 'a', 'lot', 'from', 'the', 'codes', 'you', 'write', 'in', 'the', 'board', '.', 'When', 'i', 'compare', 'my', 'codes', 'with', 'yours', 'i', 'can', 'learn', 'about', 'my', 'mistakes', 'and', 'good', 'coding', 'practices', 'that', 'i', 'should', 'follow', '.', 'There', 'fore', 'i', 'think', 'it', 'would', 'be', 'great', 'if', 'we', 'can', 'discuss', 'more', 'examples', 'in', 'the', 'class', '.', 'madam', 'explained', 'the', 'oop', 'concepts', 'clearly', 'with', 'examples.lectures', 'were', 'interesting.we', 'want', 'more', 'scenario', 'examples', 'and', 'answers', 'with', 'explanations', 'in', 'future', '.', 'I', 'satisfy', 'about', 'first', '7', 'lectures', '.', 'That', 'way', 'of', 'teaching', 'is', 'really', 'good', 'for', 'coming', 'lectures', 'too', '.', 'lectuers', 'are', 'very', 'good', '.', 'take', 'good', 'effort', 'to', 'make', 'undersatand', 'every', 'student', 'in', 'the', 'room', '.', 'very', 'helpfull', '.', 'I', 'was', 'able', 'to', 'obtain', 'a', 'clear', 'picture', 'about', 'OOP', 'and', 'its', 'concepts', '.', '``', 'lecture', 'slides', ',', 'explanations', 'were', 'very', 'clear', '.', 'it', \"'s\", 'very', 'good', 'to', 'letting', 'ask', 'questions', 'and', 'explain', 'again', 'with', 'suitable', 'examples', '.', 'sometimes', ',', 'some', 'codes', 'on', 'white', 'board', 'were', 'unclear', 'at', 'the', 'back', '.', 'overall', 'very', 'good', '!', '!', '!', \"''\", 'The', 'lectures', 'were', 'good', 'and', 'clear', '.', 'And', 'they', 'were', \"n't\", 'too', 'fast', '.', 'Writing', 'code', 'was', 'somewhat', 'confusing', 'because', 'I', 'did', \"n't\", 'know', 'java', 'before', '.', 'Actually', 'teaching', 'is', 'very', 'good', 'and', 'can', 'understand', 'easily', 'the', 'concepts', 'by', 'examples', 'which', 'are', 'given', 'in', 'the', 'class.it', 'will', 'be', 'more', 'helpful', 'if', 'provide', 'solved', 'questions', 'as', 'well', '!', '.', 'thankyou']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l9iKipZAfB2",
        "outputId": "db68af27-76d9-4647-bc4f-520fbd412130",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "tknzr = TreebankWordTokenizer()\n",
        "tknzr.tokenize(data)\n",
        "print(tokens)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Honestly', 'last', 'seven', 'lectures', 'are', 'good', '.', 'Lectures', 'are', 'understandable', '.', 'Lecture', 'slides', 'are', 'very', 'useful', 'to', 'self-study', 'also', '.', 'The', 'given', 'opportunity', 'to', 'ask', 'questions', 'from', 'the', 'lecturer', 'is', 'appreciative', '.', '``', 'Good', ':', ')', 'please', 'do', 'recap', 'at', 'class', 'starting', 'it', \"'s\", 'better', 'for', 'us', '.', 'sometimes', 'teaching', 'speed', 'is', 'very', 'high', '.', 'Thanks', '!', ':', ')', '``', 'The', 'lectures', 'are', 'good..but', 'a', 'bit', 'speed.A', 'in', 'class', 'working', 'activity', 'is', 'a', 'must', 'one.So', 'please', 'take', 'another', 'hour', 'in', 'thursdays', 'madame.', \"''\", 'We', 'can', 'hear', 'your', 'voice', 'clearly', 'and', 'can', 'understand', 'the', 'things', 'you', 'teach', '.', 'Presentation', 'slides', 'also', 'good', 'source', 'to', 'refer', '.', 'lf', 'you', 'can', 'do', 'more', 'example', 'questions', 'within', 'the', 'classroom', 'and', 'it', 'will', 'help', 'us', 'to', 'understand', 'the', 'principles', 'well.', \"''\", 'Lectures', 'was', 'well', 'structured', 'and', 'well', 'organized', '.', 'It', 'was', 'easy', 'to', 'understand', '.', 'Lecture', 'slides', 'and', 'labs', 'were', 'also', 'well', 'organized', '.', 'Lectures', 'were', 'good', '.', 'understandable', '.', 'The', 'lecture', 'slides', 'were', 'well', 'organized', 'and', 'the', 'examples', 'done', 'in', 'the', 'class', 'helped', 'a', 'lot', 'to', 'learn', 'this', 'new', 'language', 'and', 'also', 'the', 'principles', 'of', 'OOP', '.', 'Motivated', 'to', 'well', '.', 'Would', 'have', 'been', 'better', 'if', 'we', 'discussed', 'more', 'about', 'the', 'solutions', 'of', 'coding', 'exercisers', '.', 'I', 'think', 'i', 'learned', 'a', 'lot', 'from', 'the', 'codes', 'you', 'write', 'in', 'the', 'board', '.', 'When', 'i', 'compare', 'my', 'codes', 'with', 'yours', 'i', 'can', 'learn', 'about', 'my', 'mistakes', 'and', 'good', 'coding', 'practices', 'that', 'i', 'should', 'follow', '.', 'There', 'fore', 'i', 'think', 'it', 'would', 'be', 'great', 'if', 'we', 'can', 'discuss', 'more', 'examples', 'in', 'the', 'class', '.', 'madam', 'explained', 'the', 'oop', 'concepts', 'clearly', 'with', 'examples.lectures', 'were', 'interesting.we', 'want', 'more', 'scenario', 'examples', 'and', 'answers', 'with', 'explanations', 'in', 'future', '.', 'I', 'satisfy', 'about', 'first', '7', 'lectures', '.', 'That', 'way', 'of', 'teaching', 'is', 'really', 'good', 'for', 'coming', 'lectures', 'too', '.', 'lectuers', 'are', 'very', 'good', '.', 'take', 'good', 'effort', 'to', 'make', 'undersatand', 'every', 'student', 'in', 'the', 'room', '.', 'very', 'helpfull', '.', 'I', 'was', 'able', 'to', 'obtain', 'a', 'clear', 'picture', 'about', 'OOP', 'and', 'its', 'concepts', '.', '``', 'lecture', 'slides', ',', 'explanations', 'were', 'very', 'clear', '.', 'it', \"'s\", 'very', 'good', 'to', 'letting', 'ask', 'questions', 'and', 'explain', 'again', 'with', 'suitable', 'examples', '.', 'sometimes', ',', 'some', 'codes', 'on', 'white', 'board', 'were', 'unclear', 'at', 'the', 'back', '.', 'overall', 'very', 'good', '!', '!', '!', \"''\", 'The', 'lectures', 'were', 'good', 'and', 'clear', '.', 'And', 'they', 'were', \"n't\", 'too', 'fast', '.', 'Writing', 'code', 'was', 'somewhat', 'confusing', 'because', 'I', 'did', \"n't\", 'know', 'java', 'before', '.', 'Actually', 'teaching', 'is', 'very', 'good', 'and', 'can', 'understand', 'easily', 'the', 'concepts', 'by', 'examples', 'which', 'are', 'given', 'in', 'the', 'class.it', 'will', 'be', 'more', 'helpful', 'if', 'provide', 'solved', 'questions', 'as', 'well', '!', '.', 'thankyou']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0aGZ-1AGnY8",
        "outputId": "0202c201-63cf-4935-e58d-284678fa7970",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "research_data = open('/content/research_paper.txt', 'r')\n",
        "file_content = research_data.read()\n",
        "tknzr = TreebankWordTokenizer()\n",
        "tokens = tknzr.tokenize(file_content)\n",
        "print(tokens)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Neural', 'network', 'models', 'have', 'shown', 'their', 'promising', 'opportunities', 'for', 'multi-task', 'learning', ',', 'which', 'focus', 'on', 'learning', 'the', 'shared', 'layers', 'to', 'extract', 'the', 'common', 'and', 'task-invariant', 'features.', 'However', ',', 'in', 'most', 'existing', 'approaches', ',', 'the', 'extracted', 'shared', 'features', 'are', 'prone', 'to', 'be', 'contaminated', 'by', 'task-specific', 'features', 'or', 'the', 'noise', 'brought', 'by', 'other', 'tasks.', 'In', 'this', 'paper', ',', 'we', 'propose', 'an', 'adversarial', 'multi-task', 'learning', 'framework', ',', 'alleviating', 'the', 'shared', 'and', 'private', 'latent', 'feature', 'spaces', 'from', 'interfering', 'with', 'each', 'other.', 'We', 'conduct', 'extensive', 'experiments', 'on', '16', 'different', 'text', 'classification', 'tasks', ',', 'which', 'demonstrates', 'the', 'benefits', 'of', 'our', 'approach.', 'Besides', ',', 'we', 'show', 'that', 'the', 'shared', 'knowledge', 'learned', 'by', 'our', 'proposed', 'model', 'can', 'be', 'regarded', 'as', 'off-the-shelf', 'knowledge', 'and', 'easily', 'transferred', 'to', 'new', 'tasks.', 'Multi-task', 'learning', 'is', 'an', 'effective', 'approach', 'to', 'improve', 'the', 'performance', 'of', 'a', 'single', 'task', 'with', 'the', 'help', 'of', 'other', 'related', 'tasks.', 'Recently', ',', 'neural-based', 'models', 'for', 'multi-task', 'learning', 'have', 'become', 'very', 'popular', ',', 'ranging', 'from', 'computer', 'vision', '(', 'Misra', 'et', 'al.', ',', '2016', ';', 'Zhang', 'et', 'al.', ',', '2014', ')', 'to', 'natural', 'language', 'processing', '(', 'Collobert', 'andWeston', ',', '2008', ';', 'Luong', 'et', 'al.', ',', '2015', ')', ',', 'since', 'they', 'provide', 'a', 'convenient', 'way', 'of', 'combining', 'information', 'from', 'multiple', 'tasks.', 'However', ',', 'most', 'existing', 'work', 'on', 'multi-task', 'learning', '(', 'Liu', 'et', 'al.', ',', '2016c', ',', 'b', ')', 'attempts', 'to', 'divide', 'the', 'features', 'of', 'different', 'tasks', 'into', 'private', 'and', 'shared', 'spaces', ',', 'merely', 'based', 'on', 'whether', 'parameters', 'of', 'some', 'components', 'should', 'be', 'shared.', 'As', 'shown', 'in', 'Figure', '1-', '(', 'a', ')', ',', 'the', 'general', 'shared-private', 'model', 'introduces', 'two', 'feature', 'spaces', 'for', 'any', 'task', ':', 'one', 'is', 'used', 'to', 'store', 'task-dependent', 'features', ',', 'the', 'other', 'is', 'used', 'to', 'capture', 'shared', 'features.', 'The', 'major', 'limitation', 'of', 'this', 'framework', 'is', 'that', 'the', 'shared', 'feature', 'space', 'could', 'contain', 'some', 'unnecessary', 'task-specific', 'features', ',', 'while', 'some', 'sharable', 'features', 'could', 'also', 'be', 'mixed', 'in', 'private', 'space', ',', 'suffering', 'from', 'feature', 'redundancy.', 'Taking', 'the', 'following', 'two', 'sentences', 'as', 'examples', ',', 'which', 'are', 'extracted', 'from', 'two', 'different', 'sentiment', 'classification', 'tasks', ':', 'Movie', 'reviews', 'and', 'Baby', 'products', 'reviews.', 'The', 'infantile', 'cart', 'is', 'simple', 'and', 'easy', 'to', 'use.', 'This', 'kind', 'of', 'humour', 'is', 'infantile', 'and', 'boring.', 'The', 'word', '�infantile�', 'indicates', 'negative', 'sentiment', 'in', 'Movie', 'task', 'while', 'it', 'is', 'neutral', 'in', 'Baby', 'task.', 'However', ',', 'the', 'general', 'shared-private', 'model', 'could', 'place', 'the', 'task-specific', 'word', '�infantile�', 'in', 'a', 'shared', 'space', ',', 'leaving', 'potential', 'hazards', 'for', 'other', 'tasks.', 'Additionally', ',', 'the', 'capacity', 'of', 'shared', 'space', 'could', 'also', 'be', 'wasted', 'by', 'some', 'unnecessary', 'features.', 'To', 'address', 'this', 'problem', ',', 'in', 'this', 'paper', 'we', 'propose', 'an', 'adversarial', 'multi-task', 'framework', ',', 'in', 'which', 'the', 'shared', 'and', 'private', 'feature', 'spaces', 'are', 'in', 'herently', 'disjoint', 'by', 'introducing', 'orthogonality', 'constraints.Specifically', ',', 'we', 'design', 'a', 'generic', 'shared', 'private', 'learning', 'framework', 'to', 'model', 'the', 'text', 'sequence', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDxc9dT7LF_w"
      },
      "source": [
        "data = 'However, most existing work on multi-task learning (Liu et al., 2016c,b) attempts to divide the'"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZ-1aAzCJvhZ",
        "outputId": "85cb4281-ddae-478d-c8da-6ad8e76dcba7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "tokens = text_to_word_sequence(data)\n",
        "print(tokens)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['however', 'most', 'existing', 'work', 'on', 'multi', 'task', 'learning', 'liu', 'et', 'al', '2016c', 'b', 'attempts', 'to', 'divide', 'the']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOGLhxFIKdQq",
        "outputId": "39cd7155-2ca3-4d7e-db29-9d12ad6c58b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from gensim.utils import tokenize\n",
        "print(list(tokenize(data)))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['However', 'most', 'existing', 'work', 'on', 'multi', 'task', 'learning', 'Liu', 'et', 'al', 'c', 'b', 'attempts', 'to', 'divide', 'the']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbXqbagYLcph",
        "outputId": "5ff537da-5c89-475f-c8e3-7025a3459ae8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokens = TreebankWordTokenizer().tokenize(data)\n",
        "print(tokens)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['However', ',', 'most', 'existing', 'work', 'on', 'multi-task', 'learning', '(', 'Liu', 'et', 'al.', ',', '2016c', ',', 'b', ')', 'attempts', 'to', 'divide', 'the']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsKa-jcALxvC",
        "outputId": "c3feb3a1-1cb6-476d-8a00-6ed8c3d59f05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokens = nltk.word_tokenize(data)\n",
        "print(tokens)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['However', ',', 'most', 'existing', 'work', 'on', 'multi-task', 'learning', '(', 'Liu', 'et', 'al.', ',', '2016c', ',', 'b', ')', 'attempts', 'to', 'divide', 'the']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV_xbU-BXVQT"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}